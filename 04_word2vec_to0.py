import tensorflow as tf
import util 
import word2vec_utils
print(tf.__version__)
# # Model hyperparameters
# VOCAB_SIZE = 50000
# BATCH_SIZE = 128
# EMBED_SIZE = 128            # dimension of the word embedding vectors
# SKIP_WINDOW = 1             # the context window
# NUM_SAMPLED = 64            # number of negative examples to sample
# LEARNING_RATE = 1.0
# NUM_TRAIN_STEPS = 100000
# VISUAL_FLD = 'visualization'
# SKIP_STEP = 5000

# # Parameters for downloading data
# DOWNLOAD_URL = 'http://mattmahoney.net/dc/text8.zip'
# EXPECTED_BYTES = 31344016
# NUM_VISUALIZE = 3000        # number of tokens to visualize

# c = tf.random_normal([], -10, 10, seed=2)
# with tf.Session() as sess:
#     print(sess.run(c)) 
#     print(sess.run(c)) 
#     print(sess.run(c))

# with tf.Session() as sess:
#     print(sess.run(c))
#     print(sess.run(c))

# with tf.Session() as sess:
#     print(sess.run(c))

    